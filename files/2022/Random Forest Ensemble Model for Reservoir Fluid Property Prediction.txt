----- METADATA START -----
Title: Random Forest Ensemble Model for Reservoir Fluid Property Prediction
Authors: Yisa Adeeyo
Publication Date: August 2022
Reference Link: https://doi.org/10.2118/212044-MS
----- METADATA END -----



Abstract


Reservoir fluid PVT properties are measured in the laboratory for various use in reservoir engineering evaluation and estimation. Despite the indispensability of these PVT parameters, PVT lab data are seldomly available and if available may be unreliable. Instead, various empirical models have been developed and used in the industry. These empirical models are inherently inaccurate when used to predict PVT properties of fluid from different geological region with different depositional environment and fingerprint. Artificial Intelligence (AI) has evolved over the years and provided some algorithms with potentials to develop accurate predictive model for the prediction of bubblepoint pressure.This work tested some AI algorithms, compared performances and choose random forest regression algorithm in developing a robust predictive model for the estimation of bubblepoint pressure.Two thousand five hundred and twenty-two datasets obtained from oil reservoirs in different geographical locations were used for the feature scaling of input data, training and testing of the models. The independent variables, gas-oil ratio, temperature, oil density and gas density were confirmed to have key influence on the dependent variable Bubblepoint pressureThe random forest model developed uses ensemble learning approach, combines predictions from multiple machine learning algorithms by averaging all predictions to make a more accurate prediction. The ‘forest’ generated by the random forest algorithm was trained through bootstrap aggregating. This is an ensemble meta-algorithm that improves the accuracy of machine learning algorithms. Percentage data split was 70% training and 30% testing.The reliability, accuracy and completeness of the predictive model capability were computed through performance indices such as the root mean square error (RMSE) and mean absolute error (MAE). The best network architecture was determined along with the corresponding test set RMSE, and Correlation coefficient.Statistical and graphical error analysis of the results showed that the random forest model performed better than existing models with 0.98 correlation coefficients for bubblepoint pressure. Better accuracy of reservoir properties prediction could be achieved using this random forest reservoir fluid properties prediction model.




Keywords:
pvt measurement,
algorithm,
society,
artificial intelligence,
prediction,
journal,
correlation,
petroleum engineer,
random forest ensemble model,
evaluation


Subjects: 
Fluid Characterization,
Information Management and Systems,
Phase behavior and PVT measurements,
Artificial intelligence




Introduction


The pressure at which the first bubble of gas emerges from solution is known as the bubblepoint pressure. It's a crucial factor in field development plans, as well as reservoir characterization and management. Laboratory tests of reservoir oil samples are used to determine the property.


In the absence of experimental data, bubblepoint pressure can be estimated using empirical Pressure-Volume-Temperature (PVT) correlations or artificial neural network models. One or more of the following reasons could explain why empirical PVT correlations are used:


Non-representative fluid due to improper samplingExpensive sampling and laboratory analysisInadequate sample amount for a thorough analysis and/orLaboratory analysis errors


In the absence of experimental analysis, reservoir fluid properties are calculated using empirical correlations or models.


It is assumed to be empirically connected as a strong function of solution gas oil ratio (Rs), gas density (yg), oil API, and temperature (T) can be evaluated experimentally by conducting a constant-composition expansion test.


Pb=f(Rs,T,API,yg)(1)


Random Forest


Random Forest Regression is one of machine learning models, a supervised learning approach for regression that uses the ensemble learning method. The ensemble learning method combines predictions from several machine learning algorithms to produce a more accurate forecast than a single model. The structure of a typical Random Forest is illustrated in the Figure 1 


Figure 1View largeDownload slideRandom Forest ModelFigure 1View largeDownload slideRandom Forest Model Close modal


The trees run in parallel with no contact between them. During training, a Random Forest creates many decision trees and outputs the mean of the classes as the prediction of all the trees. Random Forest Regression is a powerful and precise model. It usually works well on a wide range of issues, including those with non-linear relationships. The machine learning strategies are shown in the Figure 2. The approaches include data aquistion and understanding, problem identification, ML training, ML model testing and error analysis.


Figure 2View largeDownload slideThe Machine Learning approachFigure 2View largeDownload slideThe Machine Learning approach Close modal


Literature Review


Standing [19] created the most extensively used bubblepoint pressure correlation. He developed a chart for calculating bubblepoint pressure. His graph was based on data from a small geographic area with no adjustment for oil type or non-hydrocarbon content. He analyzed 105 experimental data points from 22 distinct crude oil/natural gas combinations extracted from Californian oil fields. Standing reported a 4.8 percent average percent relative inaccuracy.


Lasater [10] used 158 experimentally measured bubblepoint pressures of 137 independent crude oil systems from the United States, Canada, and South America to build a new correlation for determining bubblepoint pressure for black oil systems. According to Lasater, the average absolute inaccuracy was 3.8 percent. The correlation is represented graphically.


The correlation for bubblepoint pressure created by Vasquez and Beggs [21] was based on mathematical manipulation of their solution GOR correlation, which was developed utilizing 5008 data points from 600 laboratory PVT investigations from various fields throughout the world. Though they claim to have used 5008 data points in the published study, the original work in the Vasquez thesis only contains 259 data points, with four of them repeated.


Glaso [9] also developed a correlation and a nomograph for bubblepoint pressure prediction. He based his findings on 45 North Sea crude oil samples. In the pressure range of 150 to 7,000 psig, Glaso reported an average absolute percent relative error of estimated saturation pressures from experimental values of 1.28 and 0.7, respectively.


Al-Marhoun [4] used 160 experimentally obtained data points from PVT analysis of 69 bottomhole fluid samples from 69 Middle Eastern oil reservoirs to build an empirical correlation for calculating bubblepoint pressure. The average relative and absolute relative error, respectively, are 0.03 percent and 3.66 percent. He also offered a graphical approach for predicting bubblepoint pressure in the form of a nomograph based on the mathematically calculated PVT correlations.


Based on the correlation developed by Al-Marhoun, Dokla and Osman [8] proposed a correlation for forecasting bubblepoint pressure (1988). 51 bottomhole samples from the United Arab Emirate (UAE) were used to create the correlation. 7.61 percent was the average absolute relative inaccuracy. The Dokla and Osman correlation is identical to Al-Marhoun [4] correlation, except with different constants. They also demonstrated how to calculate bubblepoint pressure using a nomograph.


Petrosky and Farshad [18] used 81 laboratory PVT analyses from more than 32 reservoirs offshore Texas and Louisiana to create a bubblepoint pressure correlation for Gulf of Mexico Crude Oils. With average relative and absolute errors of -0.17% and 3.28 percent, the bubblepoint pressure correlation predicts measured bubblepoint pressures.


With an average absolute error of 7.17 percent, Omar and Todd [13] created a correlation for determining bubblepoint pressure using data from Malaysian offshore oil fields in the South China Sea.


Machine Learning


Machine learning is an algorithmic framework for identifying computational models that accurately represent empirical data and the phenomena that underpin it with little or no human intervention. It uses computation techniques used by computers to learn tasks from patterns found in data. ML computation could be supervised or unsupervised.


Unsupervised Machine Learning involves asking computer to build a mapping or a clustering of objects being studied. This does not imply a variable to predict. Common methods include k means clustering, Agglomerative Hierarchical Clustering (AHC), Principal Component Analysis (PCA) etc.


Supervised Machine Learning means asking the computer to learn how to predict a variable from a set of predictors. There should be a dependent variable in the data set. This variable will be the one we wish to predict. Predictors are X variables and the variable to predict isY variable. Supervised learning algorithms include boosted tree, support vector machine, naive bayes and nearest neighbour


When Y is qualitative indicates a classification problem and when Y is quantitative it is regression problem. Supervised Machine Learning algorithms include Random Forests, K Nearest Neighbors (KNN), Support Vector Machines (SVM), Naive Bayes, Logistic Regression. In addition, each algorithm can be tuned in different ways through Hyperparameters.


There is no perfect single Algorithm/Tuning that outperforms all the others in all cases. Professional approach involves testing the performance of different tunings within different algorithms on the dataset and ultimately keep the tuned algorithm which shows the best performance, it should be noted that a performant algorithm has low Bias and Variance where Bias measures the accuracy of predictions and Variance measures how noisy the predictions are. If the performance on the training set is much higher than in the test set indicates high variance


Random Forest modelling


Mathematically, a model allows to explain one or several dependent variables using one or several independent variables through mathematical equations involving parameters coefficients. Random Forest works by generating many trees and benefit from a combined performance of the trees. It decreases bias and variance. For a new observation to predict, the prediction will be the mean of predictions from all trees.


Split the dataset into the Training set and Test set


We split the dataset into two sets Training set = learning set and Test set = validation set. Thereafter, We ask the computer to build a predictive model on the training set. We ask the computer to use the model to predict Y on the test set. We compare the prediction outomes to real Y data in the test set. If they match well, the algorithm has a good performance. we use indices to measure performance.


Training the Random Forest Regression model


The data for bubblepoint pressure function fitting problems are set up by organizing the data into two matrices, the input matrix X (oil density-rho_o, gas density- rho_g, temperature-T and solution gas oil ratio, Rs) and the target matrix T (bubblepoint pressure, Pb).


Machine Learning Random Forest Performance Measure


R2 score tells us how well our model is fitted to the data by comparing it to the average line of the dependent variable. If the score is closer to 1, then it indicates that our model performs well versus if the score is farther from 1, then it indicates that our model does not perform so well.


Another performance indice is the Mean Square Error (MSE). Mean of the squared differences between predicted Y’s and real Y’s.


MSE=1n∑1=1n(Pbestimated−Pblab)2(2)


MAPE=1n∑1=1n|Pbestimated−Pblab|(3)


n= number of observations


Prediction error also known as Root Mean Square Error (RMSE) is the Square Root of MSE.


MAPE denotes Mean Absolute Percentage Error.


Materials and Approach


Data Structure, Screening and Visualization


The data for this study came from the analysis of 500 bottomhole samples from several Niger Delta reservoirs. They were obtained from various reservoirs in Nigerian oil fields with varying chemical compositions. Table 1 presents summary statistics for each of the data variables that were selected. It contains count, mean standard deviation, minimum, maximum and percentage spread. 2349 data points were used in the bubblepoint pressure modeling.


Table 1PVT Parameters Summary Statistics   View Large


All input parameters were checked to ensure that they matched the PVT fluid property behavior of common petroleum fluids. Every row was checked, and any row with a value of zero or exceedingly high was deleted.


Outliers that didn't fit the "best" available model were eliminated. Furthermore, any value with a standardized residual greater than 2 was considered an anomaly. The model was re-fitted after all of the outliers were removed.


The PVT parameters' boxplots and histograms are displayed in Figure 3 and Figure 4. The plots depict the parameters distribution and spread.


Figure 3View largeDownload slideBoxplotsFigure 3View largeDownload slideBoxplots Close modal


Figure 4View largeDownload slideFrequency Distribution PlotsFigure 4View largeDownload slideFrequency Distribution Plots Close modal


Figure 4 shows histogram plots to inspect the frequency distribution and trend


All data used throughout the training phase were standardized to verify network consistency behaviors Adeeyo[1]. The variable value was subtracted from the mean and divided by standard deviation to achieve this standardization. The data was restricted to a range of -1 to 1.


Figure 5 shows scatterplot, heat map and correlation matrix to inspect the variables relationship and correlation. They show correlations between the stated importance of Rs, T, rho_o and rho_g to Bubblepoint pressure. The principal diagonal is a line of 1.00s that runs from top left to bottom right, illustrating that each variable is always fully correlated with itself. The same correlation is shown above the main diagonal as a mirror image of those below the main diagonal in this symmetrical matrix. A totally negative linear correlation between two variables is indicated by -1. 0 means that there is no linear relationship between two variables. A complete positive linear correlation between two variables is indicated by 1. The stronger the association between the two variables, the further the correlation coefficient is from zero. Hitherto, the linearity of the predictor variables to Bubblepoint pressure indicates Rsi with highest linearity of 0.75, T has linearity of 0.59 and rho_g has linearity of 0.13. Oil density is highly non-linear with linearity of -0.63.


Figure 5View largeDownload slideCorrelation MatrixFigure 5View largeDownload slideCorrelation Matrix Close modal


Figure 6 shows the heat map of the correlation matrix of the transformed data.


Figure 6View largeDownload slideParameter CorrelationsFigure 6View largeDownload slideParameter Correlations Close modal


Empirical Correlations Performance Measure


Practically, all existing correlations were evaluated. The correlations include Standing, Al-Marhoun, Glaso, Owolabi, Lasater, Dokla, Farshad, Al-Shammasi and Macary


Graphical analysis includes crossplot. Crossplot is a plot of the measured value versus experimental value. A perfect correlation would plot as a straight line with a slope of 45°.


Crossplots plots for the correlations are presented in Figure 8. The crossplots show that all correlations are not predicting well when the bubblepoint pressure is above 4500psi.


Figure 7View largeDownload slideExisting Correlation Cross plotsFigure 7View largeDownload slideExisting Correlation Cross plots Close modal


Figure 8View largeDownload slidePartial Dependence PlotsFigure 8View largeDownload slidePartial Dependence Plots Close modal


Table 2 shows the RMSE, MAPE, R-squared and R. RMSE ranges from 700.45 to 1696.8 while R ranges from 0.80 to 0.87.


Table 2Existing Correlations Performance   View Large


Partial Dependence Plot


n estimators and maximum depth (max_depth) are the two hyperparameters that were tuned for the model and shown in Figure 8. The red dashed lines shows the optimum values for each hyperparameter chosen by the Bayesian optimization.


The red star on the contour plot Figure 8 shows the intersection of the final sampling location at which their values were obtained.


Figure 9 shows the minimization of the objective function with increasing calls (iterations).


Figure 9View largeDownload slideConvergence plotFigure 9View largeDownload slideConvergence plot Close modal


Random Forest Model Learning Curves


In order to get an estimate of a model’s generalization performance we look at the learning curves. These are plots of the model’s performance on the training set and the validation set as a function of the training set size (or the training iteration).


The model is overfitting if it performs well on training data but performs poorly on cross-validation measures. It is underfitting if it performs poorly on both. This is one indicator of whether a model is too simple or sophisticated.


Learning curves help to figure out if adding more training instances would increase validation score. Figure 9 and 10 show the model learning curve model density plot.


Figure 10View largeDownload slideRandom Forest Learning CurvesFigure 10View largeDownload slideRandom Forest Learning Curves Close modal


Results


Table 3 shows the performance of the model.


Table 3Random Forest Bubble Point Pressure Test Performance Indices   View Large


The crossplot of the the newly developed model is shown in Figure 11. Random forest model developed achieved an accuracy R score of approximately 0.92.


Figure 11View largeDownload slideRandom Forest Density PlotFigure 11View largeDownload slideRandom Forest Density Plot Close modal


Figure 12View largeDownload slideRandom Forest Model (Testing) Cross PlotFigure 12View largeDownload slideRandom Forest Model (Testing) Cross Plot Close modal


Conclusions


We presented a newly developed machine learning random forest bubblepoint pressure prediction model. The model developed by the authors for predicting crude oil bubblepoint pressure was found to be better than the empirical correlations. This new model outperformed the existing correlations according to the statistical parameters used. The performance of the model shows that it obeyed the physical laws, does not over fit the data, which implies that it was successfully trained, can be relied on.


The difficulty of current correlations to predict Niger Delta crude increases as the bubble point pressure increases, according to this study.


This paper was selected for presentation by an SPE program committee following review of information contained in an abstract submitted by the author(s). Contents of the paper have not been reviewed by the Society of Petroleum Engineers and are subject to correction by the author(s). The material does not necessarily reflect any position of the Society of Petroleum Engineers, its officers, or members. Electronic reproduction, distribution, or storage of any part of this paper without the written consent of the Society of Petroleum Engineers is prohibited. Permission to reproduce in print is restricted to an abstract of not more than 300 words; illustrations may not be copied. The abstract must contain conspicuous acknowledgment of SPE copyright.


Nomenclature


NomenclatureAbbreviationExpansion MSEMean Square Error MAPEMean Absolute Percentage Error PbBubble point Pressure Rcorrelation coefficient R2R-Squared Rssolution gas Oil ratio, SCF/STB Stdstandard deviation Ttemperature, °F(K) rho_oOil density rho_gGas density xvariable γgaverage gas relative density (air = 1) γoOil stock tank relative density (water = 1) Haugmented matrix for EnKF KKalman gain matrix rcorrelation matrix for localization Ndtotal number of observed data (all times) Nnnumber of observed data at nth data assimilation step Nmnumber of model parameters Nenumber of ensemble members


Subscripts


SubscriptsAbbreviationExpansion ndata assimilation step number jensemble member


Superscripts


SuperscriptsAbbreviationExpansion ndata assimilation step number aanalysis fforecast


References


Adeeyo, Y. A., 2016, August2, Artificial Neural Network Modelling of Bubble point Pressure and Formation Volume Factor at Bubble point Pressure of Nigerian Crude Oil. Society of Petroleum Engineers. doi:10.2118/184378-MSGoogle Scholar Adeeyo, Y. A., & Marhoun, M.A., 2013, August5, Evaluation of Mathematical Models of PVT Properties for Nigerian Crude Oils. Society of Petroleum Engineers. doi:10.2118/167513-MSGoogle Scholar Al-Shammasi, A.A., Bubble point Pressure and Oil Formation Volume Factor Correlations. SPE Paper # 53185, 1999.Google Scholar Al-Marhoun, M.A., PVT correlations for Middle East crude oils. Journal of Petroleum Technology, 1988. 40(5): p. 650–666.Google ScholarCrossrefSearch ADS  Al-Marhoun, M.A., New Correlations for formation volume factors of oil and gas mixtures. Journal of Canadian Petroleum Technology, 1992. 31(3): p. 22–26.Google ScholarCrossrefSearch ADS  Al-Marhoun, M.A., Evaluation of empirically derived PVT properties for Middle East crude oils. Journal of Petroleum Science and Engineering, 2004. 42(2004): p. 209–221.Google Scholar Lasater, J.A. (1958, May1). Bubble Point Pressure Correlation. Society of Petroleum Engineers. doi:10.2118/957-GGoogle Scholar Mahmood, M.A. and M.A.Al-Marhoun, Evaluation of empirically derived PVT properties for Pakistani crude oils. Journal of Petroleum Science and Engineering, 1966. 16(1996): p. 275–290.Google Scholar Mahgoub, I.S., Neural Network: What it can do for Petroleum Engineers. SPE Paper # 29219, 1995.Google Scholar Omar, M. and A.Todd, Development of new modified black oil correlations for Malaysian crudes. SPE paper # 25338, 1993(1993): p. 211–219.Google Scholar Osman, M., O.A.Abdel-Wahab, and M.A.Al-Marhoun, Prediction of oil PVT properties using neural networks. SPE Paper # 68233, 2001.Google Scholar Dowla, F.U. and L.L.Rogers, Solving problems in environmental engineering and geosciences with artificial neural networks. First ed.1995, London: The MIT press. 239.Google Scholar Dokla, M. and M.Osman, Correlation of PVT Properties for UAE crudes. SPE Formation Evaluation, 1992: p. 41–46.Google Scholar Glaso, O., Generalized pressure-volume-temperature correlations. Journal of Petroleum Technology, 1980. 32(5): p. 785–795.Google ScholarCrossrefSearch ADS  Ostermanm, R. and O.Owolabi, Correlations for the reservoir fluid properties of Alaskan. SPE Paper # 11703, 1983(1983): p. 357–366.Google Scholar OloruntobaF.M. & Onyekonwu, M.O., Empirical Prediction of Bubble Point Pressure and Solution Gas Oil Ratio for Niger Delta, International Journal of Scientific & Engineering Research, Volume 7, Issue 6, June-2016520 ISSN 2229-5518Google Scholar Obomanu, D.A., Okpobiri, G.A.Correlating the PVT Properties of Nigerian Crudes. ASME.J. Energy Resour. Technol. 1987;109(4):214–217. doi:10.1115/1.3231349.Google ScholarCrossrefSearch ADS  Petrosky Jr, G.E. and F.F.Farshad, Pressure-Volume-Temperature correlations for Gulf of Mexico. SPE paper # 26644, 1993: p. 395–406.Google Scholar Standing, M.B., A Pressure-Volume-Temperature correlation for mixtures of California oil and gases. Drilling and Production Practice. Am. Pet. Inst.Tulsa OK, 1947: p. 275–287.Google Scholar Sutton, R.P. and F.F.Farshad, Evaluation of Empirically derived PVT properties for Gulf of Mexico crude oils. SPE Reservoir Engineering, 1990: p. 79–86.Google Scholar Vasquez, M.E. and H.D.Beggs, Correlation for fluid physical property prediction. Journal of Petroleum Technology, 1980. 32(6): p. 968–970.Google ScholarCrossrefSearch ADS  




Copyright 2022, Society of Petroleum Engineers DOI 10.2118/212044-MS



